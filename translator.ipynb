{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
    "        scaled = scaled.permute(1, 0, 2, 3)\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = (torch.arange(self.max_sequence_length)\n",
    "                          .reshape(self.max_sequence_length, 1))\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "\n",
    "class SentenceEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(language_to_index)\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.language_to_index = language_to_index\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "    \n",
    "    def batch_tokenize(self, batch, start_token, end_token):\n",
    "\n",
    "        def tokenize(sentence, start_token, end_token):\n",
    "            \n",
    "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
    "            if start_token:\n",
    "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
    "            if end_token:\n",
    "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
    "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
    "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
    "            return torch.tensor(sentence_word_indicies)\n",
    "\n",
    "        tokenized = []\n",
    "        for sentence_num in range(len(batch)):\n",
    "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
    "        tokenized = torch.stack(tokenized)\n",
    "        return tokenized.to(get_device())\n",
    "    \n",
    "    def forward(self, x, start_token, end_token): # sentence\n",
    "        x = self.batch_tokenize(x, start_token, end_token)\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        batch_size, sequence_length, d_model = x.size()\n",
    "        qkv = self.qkv_layer(x)\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        y = (inputs - mean) / std\n",
    "        out = self.gamma * y + self.beta\n",
    "        return out\n",
    "\n",
    "  \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        residual_x = x.clone()\n",
    "        x = self.attention(x, mask=self_attention_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual_x)\n",
    "        residual_x = x.clone()\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual_x)\n",
    "        return x\n",
    "    \n",
    "class SequentialEncoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, self_attention_mask  = inputs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length,\n",
    "                 language_to_index,\n",
    "                 START_TOKEN,\n",
    "                 END_TOKEN, \n",
    "                 PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
    "                                      for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
    "        x = self.sentence_embedding(x, start_token, end_token)\n",
    "        x = self.layers(x, self_attention_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
    "        self.q_layer = nn.Linear(d_model , d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, y, mask):\n",
    "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
    "        kv = self.kv_layer(x)\n",
    "        q = self.q_layer(y)\n",
    "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
    "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        kv = kv.permute(0, 2, 1, 3)\n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        k, v = kv.chunk(2, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
    "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
    "        out = self.linear_layer(values)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        _y = y.clone()\n",
    "        y = self.self_attention(y, mask=self_attention_mask)\n",
    "        y = self.dropout1(y)\n",
    "        y = self.layer_norm1(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer_norm2(y + _y)\n",
    "\n",
    "        _y = y.clone()\n",
    "        y = self.ffn(y)\n",
    "        y = self.dropout3(y)\n",
    "        y = self.layer_norm3(y + _y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SequentialDecoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 ffn_hidden, \n",
    "                 num_heads, \n",
    "                 drop_prob, \n",
    "                 num_layers,\n",
    "                 max_sequence_length,\n",
    "                 language_to_index,\n",
    "                 START_TOKEN,\n",
    "                 END_TOKEN, \n",
    "                 PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
    "        y = self.sentence_embedding(y, start_token, end_token)\n",
    "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                d_model, \n",
    "                ffn_hidden, \n",
    "                num_heads, \n",
    "                drop_prob, \n",
    "                num_layers,\n",
    "                max_sequence_length, \n",
    "                jpn_vocab_size,\n",
    "                eng_to_index,\n",
    "                jpn_to_index,\n",
    "                START_TOKEN, \n",
    "                END_TOKEN, \n",
    "                PADDING_TOKEN\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, eng_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, jpn_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
    "        self.linear = nn.Linear(d_model, jpn_vocab_size)\n",
    "        self.device = torch.device('cpu')\n",
    "\n",
    "    def forward(self, \n",
    "                x, \n",
    "                y, \n",
    "                encoder_self_attention_mask=None, \n",
    "                decoder_self_attention_mask=None, \n",
    "                decoder_cross_attention_mask=None,\n",
    "                enc_start_token=False,\n",
    "                enc_end_token=False,\n",
    "                dec_start_token=True, # We should make this true\n",
    "                dec_end_token=False): # x, y are batch of sentences\n",
    "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
    "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', ' ', '!', '\"', '%', '&', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '@', '—', '₂', '℃', '√', '、', '。', '々', '〆', '「', '」', '『', '』', '〜', 'ぁ', 'あ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', '゜', 'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ッ', 'ツ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ヴ', 'ヵ', 'ヶ', '・', 'ー', '一', '丁', '七', '万', '丈', '三', '上', '下', '不', '与', '世', '丘', '両', '並', '中', '丸', '丹', '主', '久', '乏', '乗', '九', '乞', '乱', '乳', '乾', '亀', '了', '予', '争', '事', '二', '云', '互', '五', '井', '些', '亡', '交', '京', '人', '仇', '今', '介', '仏', '仔', '仕', '他', '付', '仙', '代', '令', '以', '仮', '仰', '仲', '件', '任', '企', '伊', '伎', '伏', '休', '会', '伝', '伯', '伴', '伸', '伺', '似', '佇', '位', '低', '住', '体', '何', '余', '作', '併', '使', '例', '侍', '供', '依', '価', '侮', '侵', '便', '係', '促', '保', '信', '修', '俯', '俳', '俺', '倉', '個', '倍', '倒', '候', '借', '値', '倹', '偉', '偏', '停', '健', '側', '偵', '偶', '偽', '傑', '傘', '備', '催', '傲', '債', '傷', '傾', '僅', '働', '像', '僕', '僚', '僧', '儀', '儂', '億', '儚', '償', '優', '儲', '元', '兄', '充', '兆', '先', '光', '克', '免', '兎', '児', '党', '入', '全', '八', '公', '六', '共', '兵', '具', '典', '兼', '内', '円', '冊', '再', '冒', '冗', '写', '冠', '冥', '冬', '冴', '冷', '凄', '凋', '凍', '凝', '几', '凡', '処', '凧', '凪', '凶', '凹', '出', '函', '刀', '刃', '分', '切', '刈', '刊', '刑', '列', '初', '判', '別', '利', '到', '制', '刷', '券', '刺', '刻', '剃', '則', '削', '前', '剖', '剣', '剤', '剥', '剪', '副', '剰', '割', '創', '劇', '力', '功', '加', '劣', '助', '努', '励', '労', '効', '勃', '勇', '勉', '動', '勘', '務', '勝', '募', '勢', '勤', '勧', '匂', '包', '化', '北', '匹', '区', '医', '匿', '十', '千', '午', '半', '卑', '卒', '卓', '協', '南', '単', '博', '占', '卯', '印', '危', '即', '却', '卵', '卸', '厄', '厚', '原', '厨', '厳', '去', '参', '又', '及', '友', '双', '反', '収', '叔', '取', '受', '口', '古', '句', '叩', '只', '叫', '召', '可', '台', '叱', '史', '右', '叶', '号', '司', '吃', '各', '合', '吉', '吊', '同', '名', '吐', '向', '君', '吟', '吠', '否', '含', '吸', '吹', '吼', '呂', '呆', '呈', '告', '呑', '呟', '周', '味', '呻', '呼', '命', '和', '咲', '咳', '哀', '品', '員', '哲', '哺', '唄', '唇', '唐', '唖', '唯', '唱', '唸', '唾', '啄', '商', '問', '喀', '善', '喉', '喋', '喘', '喚', '喜', '喝', '喧', '喩', '喫', '喰', '営', '嗅', '嘆', '嘔', '嘘', '嘩', '噂', '噌', '噛', '器', '噴', '嚇', '囀', '囁', '囚', '四', '回', '因', '団', '困', '囲', '図', '固', '国', '圏', '園', '土', '圧', '在', '地', '坂', '均', '坊', '坐', '坪', '垂', '型', '垢', '垣', '埃', '埋', '城', '埒', '域', '埠', '執', '培', '基', '埼', '堂', '堅', '堤', '堪', '報', '場', '堵', '塀', '塁', '塊', '塔', '塗', '塞', '塩', '填', '境', '墓', '増', '墜', '墟', '墨', '墺', '壁', '壇', '壊', '壌', '士', '壮', '声', '売', '壺', '変', '夏', '夕', '外', '多', '夜', '夢', '大', '天', '太', '夫', '央', '失', '奇', '奈', '奉', '奏', '契', '奔', '套', '奢', '奥', '奨', '奪', '奮', '女', '奴', '好', '如', '妃', '妄', '妊', '妖', '妙', '妥', '妨', '妬', '妹', '妻', '姉', '始', '姑', '姓', '委', '姜', '姪', '姫', '姻', '姿', '威', '娘', '娠', '娯', '婆', '婚', '婦', '婿', '媒', '媚', '嫁', '嫉', '嫌', '嬉', '嬢', '子', '字', '存', '季', '孤', '学', '孫', '宅', '宇', '守', '安', '完', '宗', '官', '宙', '定', '宛', '宜', '宝', '実', '客', '宣', '室', '宮', '害', '宴', '宵', '家', '容', '宿', '寂', '寄', '密', '富', '寒', '寛', '寝', '察', '寡', '寧', '審', '寮', '寸', '寺', '対', '寿', '封', '専', '射', '将', '尊', '尋', '導', '小', '少', '尖', '尚', '就', '尻', '尽', '尾', '尿', '局', '屁', '居', '屈', '届', '屋', '屏', '展', '属', '屡', '層', '履', '山', '岐', '岩', '岸', '峠', '峡', '峰', '島', '峻', '崇', '崎', '崖', '崩', '嵐', '川', '州', '巡', '巣', '工', '左', '巧', '巨', '差', '己', '已', '巳', '巻', '巾', '市', '布', '希', '帝', '師', '席', '帯', '帰', '帳', '常', '帽', '幅', '幕', '幣', '干', '平', '年', '幸', '幹', '幻', '幼', '幽', '幾', '庁', '広', '床', '底', '店', '府', '度', '座', '庫', '庭', '康', '廃', '廊', '延', '廷', '建', '弁', '弄', '弊', '式', '弓', '引', '弘', '弟', '弥', '弦', '弱', '張', '強', '弾', '当', '彙', '形', '彩', '彫', '影', '役', '彼', '往', '征', '径', '待', '律', '後', '徐', '徒', '従', '得', '御', '復', '循', '微', '徳', '徴', '徹', '心', '必', '忍', '志', '忘', '忙', '応', '忠', '快', '念', '怒', '怖', '思', '怠', '急', '性', '怪', '怯', '恋', '恐', '恒', '恕', '恥', '恨', '恩', '息', '恵', '悔', '悟', '患', '悩', '悪', '悲', '悶', '情', '惑', '惚', '惜', '惨', '惰', '想', '惹', '愉', '意', '愚', '愛', '感', '慄', '慇', '慈', '態', '慌', '慎', '慕', '慢', '慣', '慨', '慮', '慰', '憂', '憊', '憎', '憐', '憑', '憤', '憧', '憩', '憲', '憶', '憾', '懃', '懇', '懐', '懲', '懸', '成', '我', '戒', '或', '戚', '戦', '戯', '戴', '戸', '戻', '房', '所', '扁', '扇', '扉', '手', '才', '打', '払', '扮', '扱', '批', '承', '技', '把', '抑', '投', '抗', '折', '抜', '択', '披', '抱', '抵', '押', '抽', '担', '拇', '拉', '拍', '拐', '拒', '拓', '拗', '拘', '招', '拝', '拠', '拡', '拭', '拳', '拵', '拶', '拷', '拾', '持', '指', '挑', '挙', '挟', '挨', '挫', '振', '挽', '挿', '捉', '捌', '捏', '捕', '捗', '捜', '捧', '捨', '据', '捻', '掃', '授', '掌', '排', '掘', '掛', '採', '探', '接', '控', '推', '措', '掲', '掴', '掻', '揃', '揉', '描', '提', '揚', '換', '握', '揮', '援', '揺', '損', '搬', '搭', '携', '搾', '摂', '摘', '摩', '撃', '撒', '撤', '撥', '撮', '撲', '擁', '擂', '操', '擦', '攫', '支', '改', '攻', '放', '政', '故', '敏', '救', '敗', '教', '敢', '散', '敬', '数', '整', '敵', '敷', '文', '斉', '斎', '斐', '斗', '料', '斜', '斤', '斬', '断', '新', '方', '施', '旅', '旋', '族', '旗', '既', '日', '旦', '旧', '旨', '早', '旬', '旱', '旺', '昆', '昇', '明', '昏', '易', '昔', '星', '映', '春', '昧', '昨', '是', '昼', '時', '晒', '晦', '晩', '普', '景', '晰', '晴', '暇', '暑', '暖', '暗', '暢', '暦', '暫', '暮', '暴', '曇', '曖', '曜', '曲', '更', '書', '曹', '替', '最', '月', '有', '服', '朗', '望', '朝', '期', '木', '未', '末', '本', '札', '机', '朽', '杏', '材', '村', '杖', '束', '条', '来', '杭', '杯', '東', '杳', '杷', '松', '板', '枇', '析', '枕', '林', '枚', '果', '枝', '枠', '枯', '架', '柄', '柑', '染', '柔', '柩', '柱', '柳', '柵', '査', '柿', '栄', '栓', '栗', '校', '株', '核', '根', '格', '栽', '桁', '桃', '案', '桜', '桟', '梅', '梗', '梨', '梯', '械', '梳', '棄', '棋', '棒', '棘', '棚', '棟', '森', '棲', '椅', '植', '椎', '椒', '検', '業', '極', '楼', '楽', '概', '構', '槌', '槍', '様', '槽', '標', '模', '権', '横', '樫', '樹', '橋', '橙', '機', '檎', '檻', '櫛', '欄', '欠', '次', '欧', '欲', '欺', '歌', '歓', '止', '正', '此', '武', '歩', '歪', '歯', '歳', '歴', '死', '殆', '殊', '残', '殖', '殴', '段', '殺', '殻', '殿', '毅', '母', '毎', '毒', '比', '毛', '毯', '氏', '民', '気', '水', '氷', '永', '氾', '汁', '求', '汗', '汚', '汝', '江', '池', '汰', '汲', '決', '汽', '沈', '沖', '沙', '没', '沢', '河', '沸', '油', '治', '沼', '沿', '況', '泉', '泊', '法', '泡', '波', '泣', '泥', '注', '泰', '泳', '洋', '洒', '洗', '洞', '津', '洩', '洪', '洲', '活', '派', '流', '浅', '浜', '浪', '浮', '浴', '海', '浸', '消', '涙', '涯', '液', '涵', '涸', '涼', '淋', '淡', '深', '淵', '混', '淹', '添', '清', '渇', '済', '渉', '渋', '減', '渡', '温', '測', '港', '湖', '湧', '湯', '湾', '湿', '満', '源', '準', '溜', '溝', '溢', '溶', '溺', '滅', '滑', '滝', '滞', '滴', '漁', '漂', '漏', '漑', '演', '漕', '漠', '漢', '漫', '漬', '漸', '潔', '潜', '潟', '潮', '潰', '澄', '澹', '激', '濁', '濃', '濡', '濫', '濯', '瀕', '瀬', '瀾', '灌', '火', '灯', '灰', '災', '炉', '炊', '炎', '炒', '炭', '点', '為', '烈', '烙', '焚', '無', '焦', '然', '焼', '煉', '煌', '煎', '煙', '照', '煩', '煮', '熊', '熟', '熱', '燃', '燥', '燭', '燼', '爆', '爛', '爪', '爬', '父', '爺', '爽', '片', '版', '牙', '牛', '牡', '牧', '物', '牲', '特', '犠', '犬', '犯', '状', '狂', '狐', '狗', '狙', '狩', '独', '狭', '狸', '狼', '猛', '猟', '猫', '献', '猶', '猿', '獄', '獣', '獰', '獲', '玄', '率', '玉', '王', '玩', '珈', '珍', '珠', '現', '球', '理', '琲', '琵', '琶', '瑞', '璧', '環', '瓜', '瓦', '瓶', '甘', '甚', '生', '産', '甥', '用', '田', '由', '甲', '申', '男', '町', '画', '界', '畏', '畑', '畔', '留', '畜', '略', '番', '異', '畳', '疎', '疑', '疫', '疱', '疲', '疹', '疾', '病', '症', '痒', '痕', '痘', '痛', '痢', '痣', '痩', '痰', '痴', '痺', '瘍', '瘡', '瘦', '療', '癇', '癌', '癒', '癖', '発', '登', '白', '百', '的', '皆', '皇', '皮', '皺', '皿', '盆', '益', '盗', '盛', '盟', '監', '盤', '盪', '目', '盲', '直', '相', '省', '眉', '看', '県', '真', '眠', '眩', '眺', '眼', '着', '睡', '督', '睨', '瞬', '瞭', '瞰', '瞳', '矍', '矢', '知', '短', '矯', '石', '砂', '研', '砕', '砦', '砲', '破', '硫', '硬', '碑', '碗', '確', '磁', '磨', '礎', '示', '礼', '社', '祈', '祉', '祖', '祝', '神', '祟', '祥', '票', '祭', '祷', '禁', '禎', '福', '禿', '秀', '私', '秋', '科', '秒', '秘', '称', '移', '稀', '程', '税', '稚', '種', '稲', '稼', '稽', '稿', '穀', '積', '穏', '穢', '穣', '穫', '穴', '究', '空', '穿', '突', '窃', '窓', '窟', '窪', '窮', '竄', '立', '竜', '章', '童', '端', '競', '竹', '笑', '笛', '符', '第', '筆', '筈', '等', '筋', '筒', '答', '策', '箇', '箋', '算', '管', '箱', '箸', '節', '範', '築', '篤', '簡', '簿', '籃', '籍', '籠', '米', '粉', '粋', '粒', '粗', '粛', '粧', '精', '糖', '糧', '糸', '系', '紀', '約', '紅', '紋', '納', '紐', '純', '紙', '級', '紛', '素', '紡', '索', '紫', '細', '紳', '紹', '紺', '終', '組', '絆', '経', '結', '絞', '絡', '給', '絨', '統', '絵', '絶', '絹', '継', '続', '維', '綱', '網', '綴', '綺', '綻', '綽', '綿', '緊', '総', '緑', '緒', '線', '締', '編', '緩', '緯', '練', '縁', '縄', '縛', '縞', '縦', '縫', '縮', '績', '繁', '繊', '繋', '繍', '織', '繕', '繰', '纂', '缶', '罠', '罪', '置', '罰', '署', '罵', '罹', '羅', '羊', '美', '群', '羨', '義', '羹', '羽', '翌', '習', '翻', '翼', '老', '考', '者', '耐', '耕', '耗', '耳', '聖', '聞', '聡', '聴', '職', '聾', '肉', '肌', '肖', '肘', '肝', '股', '肢', '肥', '肩', '肪', '肯', '育', '肴', '肺', '胃', '胆', '背', '胞', '胡', '胴', '胸', '能', '脂', '脅', '脆', '脇', '脈', '脚', '脱', '脳', '腎', '腐', '腑', '腕', '腫', '腰', '腱', '腸', '腹', '腺', '膏', '膚', '膜', '膝', '膨', '膾', '膿', '臆', '臍', '臓', '臣', '臨', '自', '臭', '至', '致', '興', '舌', '舎', '舐', '舞', '舟', '航', '般', '船', '艇', '艘', '艦', '良', '色', '艶', '芋', '芝', '芥', '芭', '芯', '花', '芸', '芻', '芽', '苔', '苗', '苛', '若', '苦', '英', '苺', '茂', '茄', '茅', '茎', '茶', '茸', '茹', '草', '荒', '荘', '荷', '莫', '菊', '菓', '菜', '華', '萄', '萎', '落', '葉', '著', '葡', '董', '葬', '葺', '蒔', '蒲', '蒸', '蒼', '蓄', '蓋', '蓼', '蔑', '蔵', '蕉', '薄', '薇', '薔', '薦', '薪', '薬', '藁', '藪', '蘇', '蘭', '虎', '虐', '虔', '虚', '虜', '虫', '虹', '蚊', '蛇', '蛍', '蛙', '蛛', '蛸', '蛾', '蜂', '蜃', '蜘', '蜜', '蜥', '蜴', '蝋', '蝙', '蝠', '蝶', '蝿', '融', '蟹', '蠣', '血', '衆', '行', '術', '街', '衛', '衝', '衣', '表', '衰', '袈', '袋', '袖', '被', '裁', '裂', '装', '裏', '裕', '補', '裟', '裡', '裸', '製', '裾', '複', '褒', '襟', '襲', '西', '要', '覆', '覇', '見', '規', '視', '覗', '覚', '覧', '親', '観', '角', '解', '触', '言', '訂', '訃', '計', '訊', '討', '訓', '記', '訛', '訝', '訟', '訣', '訪', '設', '許', '訳', '訴', '診', '証', '詐', '評', '詞', '試', '詩', '詫', '詮', '詰', '話', '詳', '誇', '誉', '誌', '認', '誓', '誕', '誘', '語', '誠', '誤', '誦', '説', '読', '誰', '課', '誼', '調', '談', '請', '諍', '論', '諜', '諦', '諸', '諺', '諾', '謀', '謎', '謙', '講', '謝', '謡', '識', '譜', '警', '議', '譲', '護', '讐', '谷', '豆', '豊', '豚', '象', '豪', '豹', '貌', '貝', '負', '財', '貢', '貧', '貨', '販', '貫', '責', '貯', '貰', '貴', '買', '貸', '費', '貼', '貿', '賀', '賂', '賃', '賄', '資', '賊', '賑', '賛', '賜', '賞', '賠', '賢', '質', '賭', '購', '贅', '贈', '贋', '赤', '赦', '走', '起', '超', '越', '趣', '足', '距', '跡', '跪', '路', '跳', '践', '踊', '踏', '踪', '蹴', '躇', '躊', '躍', '躓', '身', '躾', '車', '軌', '軍', '軒', '軟', '転', '軽', '較', '載', '輝', '輩', '輪', '輸', '轟', '轢', '辛', '辞', '辱', '農', '辺', '込', '迅', '迎', '近', '返', '迫', '述', '迷', '追', '退', '送', '逃', '逆', '透', '逐', '途', '通', '逝', '逞', '速', '造', '逢', '連', '逮', '週', '進', '逸', '遂', '遅', '遇', '遊', '運', '遍', '過', '道', '達', '違', '遜', '遠', '遡', '遣', '遥', '適', '遭', '遮', '遵', '選', '遺', '避', '還', '那', '邦', '邪', '邸', '郊', '郎', '部', '郵', '郷', '都', '配', '酎', '酒', '酔', '酢', '酬', '酵', '酷', '酸', '醜', '醤', '醸', '采', '釈', '里', '重', '野', '量', '金', '釘', '釜', '針', '釣', '鈍', '鈴', '鉄', '鉛', '鉢', '鉱', '銀', '銃', '銅', '銘', '銭', '鋭', '鋼', '錆', '錐', '錠', '錨', '錯', '録', '鍋', '鍛', '鍮', '鍵', '鍼', '鎖', '鎮', '鏡', '鐘', '鑑', '鑠', '長', '門', '閉', '開', '閏', '閑', '間', '関', '閣', '闇', '闘', '阜', '阪', '防', '阻', '阿', '降', '限', '陛', '院', '陣', '除', '陥', '陪', '陰', '陳', '陶', '陸', '険', '陽', '隅', '隊', '階', '随', '隔', '隕', '隙', '際', '障', '隠', '隣', '隷', '隻', '雀', '雄', '雅', '集', '雇', '雌', '雑', '雛', '離', '難', '雨', '雪', '雫', '雰', '雲', '零', '雷', '雹', '電', '需', '震', '霊', '霜', '霧', '露', '青', '静', '非', '面', '革', '靴', '鞄', '鞍', '鞘', '鞭', '韓', '音', '響', '頁', '頂', '頃', '項', '順', '須', '預', '頑', '頓', '領', '頬', '頭', '頷', '頻', '頼', '題', '額', '顎', '顔', '顕', '願', '類', '顧', '風', '飛', '食', '飢', '飯', '飲', '飴', '飼', '飽', '飾', '餅', '養', '餌', '餓', '館', '饉', '首', '香', '馬', '馳', '馴', '駄', '駅', '駆', '駐', '駒', '駝', '駟', '駱', '騒', '験', '騙', '騰', '驚', '骨', '骸', '髄', '高', '髪', '髭', '鬆', '鬱', '鬼', '魂', '魃', '魅', '魔', '魘', '魚', '鮫', '鮭', '鮮', '鯉', '鯔', '鯖', '鯨', '鰌', '鰻', '鱒', '鱗', '鳥', '鳩', '鳴', '鳶', '鶏', '鶴', '鷲', '鷹', '鹸', '鹿', '麓', '麗', '麦', '麺', '麻', '黄', '黒', '黙', '鼓', '鼠', '鼻', '齢', '龍', '！', '＄', '％', '（', '）', '＋', '，', '－', '．', '０', '１', '２', '３', '４', '５', '６', '７', '８', '９', '：', '＝', '？', '～', '｡', '｣', '\\x00', '<eos>']\n",
      "['<sos>', ' ', '!', '\"', '$', '%', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '¥', '°', 'é', 'ñ', 'ō', '—', '’', '“', '”', '₂', '€', '\\x00', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "sentences_eng = []\n",
    "eng_vocab = []\n",
    "sentences_jpn = []\n",
    "jpn_vocab = []\n",
    "counter = 0\n",
    "\n",
    "START_TOKEN = '<sos>'\n",
    "PADDING_TOKEN = '\\0'\n",
    "END_TOKEN = '<eos>'\n",
    "\n",
    "\n",
    "eng_vocab_set = set(eng_vocab)\n",
    "jpn_vocab_set = set(jpn_vocab)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open('jpn.txt', 'r', encoding= 'utf-8') as file:\n",
    "    for line in file:\n",
    "        sentences = line.split('\\t')\n",
    "        english_sentence = sentences[0]\n",
    "        japanese_sentence = sentences[1]\n",
    "\n",
    "        sentences_jpn.append(japanese_sentence)\n",
    "        sentences_eng.append(english_sentence)\n",
    "\n",
    "        for l in english_sentence:\n",
    "            if l not in eng_vocab_set:\n",
    "                eng_vocab_set.add(l)\n",
    "                eng_vocab.append(l)\n",
    "        \n",
    "        for k in japanese_sentence:\n",
    "            if k not in jpn_vocab_set:\n",
    "                jpn_vocab_set.add(k)\n",
    "                jpn_vocab.append(k)\n",
    "\n",
    "eng_vocab.sort()\n",
    "jpn_vocab.sort()\n",
    "\n",
    "jpn_vocab = [char for char in jpn_vocab if not (char.isalpha() and char.islower())]\n",
    "jpn_vocab = [char for char in jpn_vocab if not (char.isalpha() and char.isupper())]\n",
    "jpn_vocab = [char for char in jpn_vocab if char != '\\u3000']\n",
    "\n",
    "eng_vocab.insert(0, START_TOKEN)\n",
    "eng_vocab.append(PADDING_TOKEN)\n",
    "eng_vocab.append(END_TOKEN)\n",
    "\n",
    "jpn_vocab.insert(0, START_TOKEN)\n",
    "jpn_vocab.append(PADDING_TOKEN)\n",
    "jpn_vocab.append(END_TOKEN)\n",
    "\n",
    "print(jpn_vocab)\n",
    "print(eng_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length Japanese: 28.0\n",
      "97th percentile length English: 60.0\n",
      "['go.', 'go.', 'hi.', 'hi.', 'hi.', 'hi.', 'run.', 'run.', 'who?', 'wow!']\n",
      "['行け。', '行きなさい。', 'こんにちは。', 'もしもし。', 'やっほー。', 'こんにちは！', '走れ。', '走って！', '誰？', 'すごい！']\n"
     ]
    }
   ],
   "source": [
    "index_to_jpn = {k:v for k,v in enumerate(jpn_vocab)}\n",
    "jpn_to_index = {v:k for k,v in enumerate(jpn_vocab)}\n",
    "index_to_eng = {k:v for k,v in enumerate(eng_vocab)}\n",
    "eng_to_index = {v:k for k,v in enumerate(eng_vocab)}\n",
    "\n",
    "sentences_eng = [sentence.rstrip('\\n').lower() for sentence in sentences_eng]\n",
    "sentences_jpn = [sentence.rstrip('\\n') for sentence in sentences_jpn]\n",
    "\n",
    "PERCENTILE = 97\n",
    "print(f\"{PERCENTILE}th percentile length Japanese: {np.percentile([len(s) for s in sentences_jpn], PERCENTILE)}\")\n",
    "print(f\"{PERCENTILE}th percentile length English: {np.percentile([len(s) for s in sentences_eng], PERCENTILE)}\")\n",
    "\n",
    "print(sentences_eng[:10])\n",
    "print(sentences_jpn[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 104785\n",
      "Number of valid sentences: 104493\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(sentences_jpn)):\n",
    "    japanese_sentence, english_sentence = sentences_jpn[index], sentences_eng[index]\n",
    "    if is_valid_length(japanese_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(japanese_sentence, jpn_vocab):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences_jpn)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104493\n",
      "104493\n"
     ]
    }
   ],
   "source": [
    "japanese_sentences = [sentences_jpn[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [sentences_eng[i] for i in valid_sentence_indicies]\n",
    "\n",
    "print(len(english_sentences))\n",
    "print(len(japanese_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "jpn_vocab_size = len(jpn_vocab)\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          jpn_vocab_size,\n",
    "                          eng_to_index,\n",
    "                          jpn_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(92, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(2495, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=2495, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('go.', 'go.', 'hi.', 'hi.', 'hi.', 'hi.', 'run.', 'run.', 'who?', 'wow!', 'wow!', 'wow!', 'wow!', 'duck!', 'duck!', 'fire!', 'fire!', 'fire!', 'help!', 'help!', 'hide.', 'jump!', 'jump!', 'jump!', 'jump!', 'jump!', 'jump.', 'jump.', 'jump.', 'jump.'), ('行け。', '行きなさい。', 'こんにちは。', 'もしもし。', 'やっほー。', 'こんにちは！', '走れ。', '走って！', '誰？', 'すごい！', 'ワォ！', 'わぉ！', 'おー！', '頭を下げろ！', '伏せて！', '火事だ！', '火事！', '撃て！', '助けて！', '助けてくれ！', '隠れろ。', '飛び越えろ！', '跳べ！', '飛び降りろ！', '飛び跳ねて！', 'ジャンプして！', '跳べ！', '飛び跳ねて！', 'ジャンプして！', '跳んで。')]\n",
      "[('stop!', 'stop!', 'wait!', 'wait!', 'wait!', 'wait.', 'wait.', 'go on.', 'go on.', 'go on.', 'go on.', 'hello!', 'hello!', 'hello!', 'hello.', 'hello.', 'hurry!', 'i see.', 'i see.', 'i see.', 'i see.', 'i see.', 'i see.', 'i see.', 'i try.', 'i try.', 'i try.', 'i try.', 'i try.', 'i won!'), ('やめろ！', '止まれ！', '待って！', '待ってろよ。', '待ってくれ。', '待ってろよ。', '待ってくれ。', '続けて。', '進んで。', '進め。', '続けろ。', 'こんにちは。', 'もしもし。', 'こんにちは！', 'もしもし。', 'やあ！', '急げ！', 'なるほど。', 'なるほどね。', 'わかった。', 'わかりました。', 'そうですか。', 'そうなんだ。', 'そっか。', '頑張ってみる。', 'やってみる。', '試してみる。', 'やってみよう！', 'トライしてみる。', '俺の勝ちー！')]\n",
      "[('i won!', 'i won!', 'i won!', 'i won!', 'oh no!', 'oh no!', 'oh no!', 'oh no!', 'oh no!', 'oh no!', 'relax.', 'relax.', 'relax.', 'relax.', 'shoot!', 'smile.', 'smile.', 'cheers!', 'freeze!', 'get up.', 'get up.', 'get up.', 'go now.', 'got it!', 'got it!', 'he ran.', 'he ran.', 'hop in.', 'hop in.', 'hug me.'), ('勝ったぁ！', '勝ったぞ！', '私の勝ち！', '私が勝ち！', 'なんてこった！', 'なんてことだ！', 'しまった！', 'あー、しまった！', 'うわ、しまった！', '何てことだ！', '落ち着いて。', 'くつろいで。', 'リラックスして。', '楽にしてください。', '撃て！', 'はい、チーズ。', 'にっこり笑って。', '乾杯！', '動くな！', '起きなさい！', '起きなさい。', '起きろ！', 'さあ、行っといで。', '捕まえた。', '分かった！', '彼は走った。', '彼が走った。', '乗れよ。', 'さあ乗って。', '抱きしめて。')]\n",
      "[('hug me.', 'i know.', 'i know.', 'i left.', 'i lost.', 'i paid.', 'i quit.', 'i quit.', 'i quit.', \"i'm 19.\", \"i'm ok.\", \"i'm ok.\", \"i'm up.\", \"i'm up.\", 'listen.', 'listen.', 'no way!', 'no way!', 'no way!', 'no way!', 'no way!', 'no way!', 'no way!', 'really?', 'really?', 'really?', 'really?', 'thanks!', 'thanks!', 'thanks!'), ('ぎゅーして。', '分かってる。', '分かってます。', '出発した。', '負けた・・・。', '払いました。', '辞職します。', '私、辞めます。', 'やめた。', '１９歳です。', '大丈夫ですよ。', '私は大丈夫です。', '目は覚めています。', '起きてるよ。', '聞きなさい。', '聞いて！', '馬鹿な！', 'まさか！', 'あり得ねぇー。', 'とんでもない！', 'とんでもございません！', 'とんでもありません！', 'そんなバカな！', '本当？', '本当に？', '本気？', 'マジか。', 'ありがとう。', 'どうも！', 'あざっす！')]\n",
      "[('thanks.', 'thanks.', 'thanks.', 'thanks.', 'thanks.', 'we try.', 'we won.', 'we won.', 'why me?', 'why me?', 'am i ok?', 'ask tom.', 'ask tom.', 'ask tom.', 'awesome!', 'awesome!', 'be calm.', 'be cool.', 'be cool.', 'be good.', 'be good.', 'be good.', 'be nice.', 'be nice.', 'beat it.', 'call me.', 'call me.', 'call us.', 'come in.', 'come in.'), ('ありがとうございます！', 'お疲れさまでした。', 'ありがとう。', 'おおきに！', 'ありがとよ。', '私たちは努力しております。', '俺らの勝ちー！', '勝ったぞ！', '何でわたしなの？', 'どうして私なの？', '僕、大丈夫かな？', 'トムに聞きなさい。', 'トムに聞いて。', 'トムに聞いてごらん。', 'すごいぞ！', 'すっげー！', '落ち着いて。', '落ち着いて。', '冷静に。', 'いい子にしなさい。', 'いい子にしときなさい。', 'おとなしくしなさい。', 'お行儀よくしなさい。', '優しくしてあげなさい。', 'どっか行け。', '連絡をちょうだい。', '電話してね。', 'お電話ください。', '入っておいでよ。', 'お入りください。')]\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, english_sentences, japanese_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.japanese_sentences = japanese_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.english_sentences[index], self.japanese_sentences[index]\n",
    "    \n",
    "dataset = TextDataset(english_sentences, japanese_sentences)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)\n",
    "\n",
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if(batch_num > 3):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.CrossEntropyLoss(ignore_index = jpn_to_index[PADDING_TOKEN],\n",
    "                                reduction = 'none')\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr = 1e-4)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFINITY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, jpn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal = 1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for index in range(num_sentences):\n",
    "        eng_sentence_length, jpn_sentence_length = len(eng_batch[index]), len(jpn_batch[index])\n",
    "        eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "        jpn_chars_to_padding_mask = np.arange(jpn_sentence_length + 1, max_sequence_length)\n",
    "        encoder_padding_mask[index, :, eng_chars_to_padding_mask] = True\n",
    "        encoder_padding_mask[index, eng_chars_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_self_attention[index, :, jpn_chars_to_padding_mask] = True\n",
    "        decoder_padding_mask_self_attention[index, jpn_chars_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_cross_attention[index, :, eng_chars_to_padding_mask] = True\n",
    "        decoder_padding_mask_cross_attention[index, jpn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFINITY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFINITY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFINITY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0 : 8.143197059631348\n",
      "English: go.\n",
      "Japanese Translation: 行け。\n",
      "Japanese Prediction: 然価然価停停然停儲儲停鉱痛痛処函処廊函函儲函儲函処処処処函函函函函函函函函函頑函或偶念念察念念念念函儲頑儲涙停儲林林函林林頑儲函儲或函函函函函函函函函函函易函易函函函易函函函躾函函函易偶携函函函或函函函函函函函函函函函函函函函函函函函偶函函函函虎処函易函虎偶偶函函函函函易函函函函易函函函函偶函偶函函停函函活案曜縄函函函函函函函縄儲澄処泣縄函函縄処函函函函函憤印函躍函函躍函覇議函乱議携板函函函函虎函\n",
      "Evaluation translation (should we go to the mall?) : ('詫然詫然然然然然外外！退退詫然然然安安安運然然呟呟処処処処処処争争争函！！！！呟呟呟呟呟呟！！！呟呟呟頑頑頑携呟呟呟呟呟携携函呟呟呟呟呟函函函函詫詫詫函鶴函函呟呟函函函函函函函函函呟呟携携携鋼鋼鋼函呟呟呟函函函函函函函函函函函函函函函函鞄鞄鞄虎虎函函函容呟呟呟呟函函函函函函函函函函呟呟呟呟呟呟函函函函呟呟活活活活函函函函直直直直直容容容容容容退退活活活活活活活詫詫詫躍退函函函呟呟呟呟呟函函函携詫詫',)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask \u001b[39m=\u001b[39m create_masks(eng_batch, jpn_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m jpn_predictions \u001b[39m=\u001b[39m transformer(eng_batch,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                              jpn_batch,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                              encoder_self_attention_mask\u001b[39m.\u001b[39;49mto(device), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                              decoder_self_attention_mask\u001b[39m.\u001b[39;49mto(device), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                              decoder_cross_attention_mask\u001b[39m.\u001b[39;49mto(device),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                              enc_start_token\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                              enc_end_token\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                              dec_start_token\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                              dec_end_token\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m labels \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39msentence_embedding\u001b[39m.\u001b[39mbatch_tokenize(jpn_batch, start_token\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, end_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss \u001b[39m=\u001b[39m criterian(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     jpn_predictions\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, jpn_vocab_size)\u001b[39m.\u001b[39mto(device),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=285'>286</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=286'>287</a>\u001b[0m             x, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=287'>288</a>\u001b[0m             y, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=293'>294</a>\u001b[0m             dec_start_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m# We should make this true\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=294'>295</a>\u001b[0m             dec_end_token\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m): \u001b[39m# x, y are batch of sentences\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=295'>296</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, encoder_self_attention_mask, start_token\u001b[39m=\u001b[39;49menc_start_token, end_token\u001b[39m=\u001b[39;49menc_end_token)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=296'>297</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token\u001b[39m=\u001b[39mdec_start_token, end_token\u001b[39m=\u001b[39mdec_end_token)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=297'>298</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(out)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, self_attention_mask, start_token, end_token):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_embedding(x, start_token, end_token)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x, self_attention_mask)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m x, self_attention_mask  \u001b[39m=\u001b[39m inputs\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     x \u001b[39m=\u001b[39m module(x, self_attention_mask)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m residual_x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m residual_x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mclone()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mffn(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m residual_x)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\UCF\\Classes\\Current Classes\\EEL 4815 Concepts in Machine Learning\\Project\\translator.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear2(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/UCF/Classes/Current%20Classes/EEL%204815%20Concepts%20in%20Machine%20Learning/Project/translator.ipynb#X16sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, jpn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, jpn_batch)\n",
    "        optim.zero_grad()\n",
    "        jpn_predictions = transformer(eng_batch,\n",
    "                                     jpn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        \n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(jpn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            jpn_predictions.view(-1, jpn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == jpn_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Japanese Translation: {jpn_batch[0]}\")\n",
    "            jpn_sentence_predicted = torch.argmax(jpn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for index in jpn_sentence_predicted:\n",
    "              if index == jpn_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_jpn[index.item()]\n",
    "            print(f\"Japanese Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            jpn_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, jpn_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          jpn_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_jpn[next_token_index]\n",
    "                jpn_sentence = (jpn_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {jpn_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
